<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>CentOS7 FTP安装与配置</title>
      <link href="/2020/03/01/centos-vsftpd-setup/"/>
      <url>/2020/03/01/centos-vsftpd-setup/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文由 <a href="http://ksria.com/simpread/" target="_blank" rel="noopener">简悦 SimpRead</a> 转码， 原文地址 <a href="https://www.cnblogs.com/haiyabtx/p/10762745.html" target="_blank" rel="noopener">https://www.cnblogs.com/haiyabtx/p/10762745.html</a></p></blockquote><h2 id="1、FTP-的安装"><a href="#1、FTP-的安装" class="headerlink" title="1、FTP 的安装"></a>1、FTP 的安装</h2><pre><code class="bash">#安装yum install -y vsftpd#设置开机启动systemctl enable vsftpd.service#启动systemctl start vsftpd.service#停止systemctl stop vsftpd.service#查看状态systemctl status vsftpd.service</code></pre><h2 id="2、配置-FTP"><a href="#2、配置-FTP" class="headerlink" title="2、配置 FTP "></a>2、配置 FTP </h2><pre><code class="bash">#打开配置文件vim /etc/vsftpd/vsftpd.conf#显示行号:set number#修改配置 12 行anonymous_enable=NO#修改配置 33 行anon_mkdir_write_enable=YES#修改配置48行chown_uploads=YES#修改配置72行async_abor_enable=YES#修改配置82行ascii_upload_enable=YES#修改配置83行ascii_download_enable=YES#修改配置86行ftpd_banner=Welcome to blah FTP service.#修改配置100行chroot_local_user=YES#添加下列内容到vsftpd.conf末尾use_localtime=YESlisten_port=21idle_session_timeout=300guest_enable=YESguest_username=vsftpduser_config_dir=/etc/vsftpd/vconfdata_connection_timeout=1virtual_use_local_privs=YESpasv_min_port=40000pasv_max_port=40010accept_timeout=5connect_timeout=1allow_writeable_chroot=YES</code></pre><h2 id="3、建立用户文件"><a href="#3、建立用户文件" class="headerlink" title="3、建立用户文件"></a>3、建立用户文件</h2><pre><code class="bash">#创建编辑用户文件vim /etc/vsftpd/virtusers#第一行为用户名，第二行为密码。不能使用root作为用户名 leo12345</code></pre><h2 id="4、生成用户数据文件"><a href="#4、生成用户数据文件" class="headerlink" title="4、生成用户数据文件"></a>4、生成用户数据文件</h2><pre><code class="bash">db_load -T -t hash -f /etc/vsftpd/virtusers /etc/vsftpd/virtusers.db#设定PAM验证文件，并指定对虚拟用户数据库文件进行读取chmod 600 /etc/vsftpd/virtusers.db </code></pre><h2 id="5、修改-etc-pam-d-vsftpd-文件"><a href="#5、修改-etc-pam-d-vsftpd-文件" class="headerlink" title="5、修改 /etc/pam.d/vsftpd 文件"></a>5、修改 /etc/pam.d/vsftpd 文件</h2><pre><code class="bash"># 修改前先备份 cp /etc/pam.d/vsftpd /etc/pam.d/vsftpd.bakvi /etc/pam.d/vsftpd#先将配置文件中原有的 auth 及 account 的所有配置行均注释掉auth sufficient /lib64/security/pam_userdb.so db=/etc/vsftpd/virtusers account sufficient /lib64/security/pam_userdb.so db=/etc/vsftpd/virtusers # 如果系统为32位，上面改为lib</code></pre><h2 id="6、新建系统用户-vsftpd，用户目录为-home-vsftpd"><a href="#6、新建系统用户-vsftpd，用户目录为-home-vsftpd" class="headerlink" title="6、新建系统用户 vsftpd，用户目录为 / home/vsftpd"></a>6、新建系统用户 vsftpd，用户目录为 / home/vsftpd</h2><pre><code class="bash">#用户登录终端设为/bin/false(即：使之不能登录系统)useradd vsftpd -d /home/vsftpd -s /bin/falsechown -R vsftpd:vsftpd /home/vsftpd</code></pre><h2 id="7、建立虚拟用户个人配置文件"><a href="#7、建立虚拟用户个人配置文件" class="headerlink" title="7、建立虚拟用户个人配置文件"></a>7、建立虚拟用户个人配置文件</h2><pre><code class="bash">mkdir /etc/vsftpd/vconfcd /etc/vsftpd/vconf#这里建立虚拟用户leo配置文件touch leo#编辑leo用户配置文件，内容如下，其他用户类似vi leolocal_root=/home/vsftpd/leo/write_enable=YESanon_world_readable_only=NOanon_upload_enable=YESanon_mkdir_write_enable=YESanon_other_write_enable=YES#建立leo用户根目录mkdir -p /home/vsftpd/leo/</code></pre><h2 id="8、防火墙设置"><a href="#8、防火墙设置" class="headerlink" title="8、防火墙设置"></a>8、防火墙设置</h2><pre><code class="bash">IPtables 的设置方式：vi /etc/sysconfig/iptables#编辑iptables文件，添加如下内容，开启21端口-A INPUT -m state --state NEW -m tcp -p tcp --dport 21 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 40000:40010 -j ACCEPTfirewall 的设置方式：firewall-cmd --zone=public --add-service=ftp --permanentfirewall-cmd --zone=public --add-port=21/tcp --permanentfirewall-cmd --zone=public --add-port=40000-40010/tcp --permanent </code></pre><h2 id="9、重启-vsftpd-服务器"><a href="#9、重启-vsftpd-服务器" class="headerlink" title="9、重启 vsftpd 服务器"></a>9、重启 vsftpd 服务器</h2><pre><code class="bash">systemctl restart vsftpd.service</code></pre><h2 id="10、使用-ftp-工具连接测试"><a href="#10、使用-ftp-工具连接测试" class="headerlink" title="10、使用 ftp 工具连接测试"></a>10、使用 ftp 工具连接测试</h2><p>这个时候，使用 ftp 的工具连接时，我们发现是可以连接的。传输文件的时候，会发现文件上传和下载都会出现</p><p>500、503 、200 等问题。这个时候，可以进行以下操作：</p><h3 id="方式一、关闭-SELINUX"><a href="#方式一、关闭-SELINUX" class="headerlink" title="方式一、关闭 SELINUX"></a>方式一、关闭 SELINUX</h3><pre><code class="bash">#打开SELINUX配置文件vim /etc/selinux/config#修改配置参数#注释  SELINUX=enforcing#增加  SELINUX=disabled#修改完成后，需要重启！</code></pre><h3 id="方式二、修改-SELINUX"><a href="#方式二、修改-SELINUX" class="headerlink" title="方式二、修改 SELINUX"></a>方式二、修改 SELINUX</h3><pre><code class="bash">#暂时让SELinux进入Permissive模式setenforce 0 #列出与ftp相关的设置getsebool -a|grep ftp#以下是显示出来的权限，off是关闭权限，on是打开权限。不同的机器显示的可能不一样。我看了我的显示的，和网上其他教程就不太一样ftp_home_dir --&gt; offftpd_anon_write --&gt; offftpd_connect_all_unreserved --&gt; offftpd_connect_db --&gt; offftpd_full_access --&gt; offftpd_use_cifs --&gt; offftpd_use_fusefs --&gt; offftpd_use_nfs --&gt; offftpd_use_passive_mode --&gt; offhttpd_can_connect_ftp --&gt; offhttpd_enable_ftp_server --&gt; offsftpd_anon_write --&gt; offsftpd_enable_homedirs --&gt; offsftpd_full_access --&gt; offsftpd_write_ssh_home --&gt; offtftp_anon_write --&gt; offtftp_home_dir --&gt; off#将包含有 ftp_home_dir 和 ftpd_full_access 相关的都设置为 1setsebool -P ftp_home_dir 1setsebool -P allow_ftpd_anon_write 1setsebool -P ftp_home_dir 1setenforce 1 #进入Enforcing模式</code></pre><h3 id="方式三、-SELINUX-不对-vsftp-不做任何限制"><a href="#方式三、-SELINUX-不对-vsftp-不做任何限制" class="headerlink" title="方式三、 SELINUX 不对 vsftp 不做任何限制"></a>方式三、 <em>SELINUX 不对 vsftp 不做任何限制</em></h3><pre><code class="bash">setsebool -P ftpd_connect_all_unreserved 1</code></pre><p>这个时候再使用工具连接，你发现，就可以正常的上传和下载文件了。</p><p>如果还是有问题尝试给我们用户的 ftp 目录，设置一下操作权限</p><pre><code class="bash">chmod -R 775 /home/vsftpd/leo</code></pre><h3 id="FTP-目录权限"><a href="#FTP-目录权限" class="headerlink" title="FTP 目录权限"></a>FTP 目录权限</h3><p>其它位置复制过来的文件要更改用户所有权，比如更改网站目录到FTP</p><pre><code class="bash">#chown [-R] 账号名称:组群  文件/目录chown -R vsftpd:vsftpd www#www用户加入vsftpd用户权#usermod -a -G {用户组名} {用户名}usermod -a -G vsftpd www#chmod -R g+rwx {文件名}chmod -R g+rwx vsftpd#直接给所用权限也可以chmod -R a+rwx vsftpd</code></pre><h3 id="FTP工具设置"><a href="#FTP工具设置" class="headerlink" title="FTP工具设置"></a>FTP工具设置</h3><ul><li>加密方式：只使用明文FTP</li><li>传输设置：主动</li></ul>]]></content>
      
      
      <categories>
          
          <category> 安装部署 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FTP </tag>
            
            <tag> Centos </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于 Tendermint 的区块链漂流瓶简单实现</title>
      <link href="/2020/02/29/tendermint-demo-msg-bottle/"/>
      <url>/2020/02/29/tendermint-demo-msg-bottle/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文由 <a href="http://ksria.com/simpread/" target="_blank" rel="noopener">简悦 SimpRead</a> 转码， 原文地址 <a href="https://www.cnblogs.com/newton/p/9611340.html" target="_blank" rel="noopener">https://www.cnblogs.com/newton/p/9611340.html</a></p></blockquote><p>本文主要借 demo 介绍基于 Tendermint 的区块链应用开发，这个 demo 很简单，主要包含以下功能：</p><ol><li>扔漂流瓶</li><li>捞漂流瓶</li><li>之后投放者和打捞者可以相互传递 [加密] 信息</li></ol><p>代码已上传至 <a href="https://github.com/tuoxieyz/driftbottle" target="_blank" rel="noopener">github</a>。</p><p><strong>Tendermint</strong></p><p>Tendermint 帮我们实现了 PBFT，相当于搭了一个共识框架，包含两部分：</p><ul><li>Tendermint-core：PBFT 共识算法实现；</li><li>Tendermint-abci：定义了应用须实现的接口和调用规则，还实现了与外部通信的 socket-server。官方的这部分源码可以看做是 Go-abci，我们也可以根据需要编写其它语言的 xxx-abci。</li></ul><p>可以将其类比为传统应用的开发框架（如 MVC），而我们要做的就是基于 abci 编写具体的区块链逻辑（为方便和清晰起见，本文用 Go 编写具体逻辑，自然 abci 就用官方的了），这就实现了服务端；而用户也需要一个客户端用来与区块链交互。</p><p><img src="/2020/02/29/tendermint-demo-msg-bottle/474041-20180926105447752-2024285703.png" alt></p><p>以上，Tendermint、服务端逻辑、客户端，三者组成了一个完整的区块链应用。</p><p><strong>数据库</strong></p><p>在动手编码之前，要考虑数据存储的问题，选择文本文件还是 Oracle 呢？区块链网络里大部分是普通电子设备，使用者亦是普通人，让他们事先安装大型数据库显然不现实，更不用说区块链本身不会出现复杂操作数据的业务。另外由于全节点数据的完备性，用不着通过网络去其它设备上查询数据，很多数据库自带的网络服务也不需要（SPV 这种，业务单一，完全可以单独开放一个远程接口）。而文本文件、excel 之类的，只适合人类使用，根本不能算作数据引擎。我们需要的是一个满足基本 CUID 的高效的本地数据库，目前大多区块链使用 LevelDB 作为存储引擎，这是 C/C++ 编写的本地 kv 数据库，原作者也写了 <a href="https://github.com/syndtr/goleveldb" target="_blank" rel="noopener">Go 实现的版本</a>，其原理可参看 <a href="https://blog.csdn.net/qq_26499321/article/details/78063856" target="_blank" rel="noopener">半小时学会 LevelDB 原理及应用</a> ，godoc 地址：<a href="https://godoc.org/github.com/syndtr/goleveldb/leveldb" target="_blank" rel="noopener">https://godoc.org/github.com/syndtr/goleveldb/leveldb</a>。LevelDB 总体上采用了 LSM-Tree 的设计思想（LSM-Tree 的虽说是数据结构，但更偏重于设计思路）。</p><p><em>LevelDB 同时只能被一个进程使用。另，以太坊的数据存储于 / chaindata 目录下，运行后其下会生成一坨. ldb 文件，而非网上常说的 sst 文件，这可能是跟 13 年的一次版本更新有关，<a href="https://github.com/google/leveldb/commit/0b9a89f40efdd143fa1426e7d5cd997f67ba6361" target="_blank" rel="noopener">Release LevelDB 1.14</a>。另：LevelDB 的 k-v 模式（顺序读效率不高）不适合 relationship，即不适合有一定数据关联度的业务场景。</em></p><p>为方便使用，可以封装一些常用的数据库操作。顺便尝试下提供新操作的几种思路。</p><ol><li><p>直接给 leveldb.DB 增加新方法：  </p><pre><code>// 给leveldb.DB增加Set方法func (db *leveldb.DB) Set(key []byte, value []byte) {    //...    err := db.Put(key, value, nil)    //...}</code></pre><p>然而，给一个类型新增方法只能在该类型同个 package 中，否则编译时会报 “Cannot define new methods on non-local type XXXX” 的错误。此时，可以怀念下 C# 的扩展方法。</p></li><li><p>既然无法在外部修改 leveldb.DB 的方法集，那么就在当前 package 建一个继承 leveldb.DB 的 struct，即内嵌一个 leveldb.DB 类型字段， type GoLevelDB struct { *leveldb.DB } ，然后将上述代码的指针类型改为 * GoLevelDB 即可，很完美。不过，在封装 Get 方法的时候出问题了：  </p><pre><code>func (db *GoLevelDB) Get(key []byte) []byte {    //...    //Go不支持重载，或者说Go只把方法名作为唯一签名。    //这里原意是调用的父类的Get方法，但该方法被当前类的Get方法覆盖了，参数不一致导致编译失败    res, err := db.Get(key, nil)    //...    return res}</code></pre></li></ol><pre><code>不支持重载，只能修改子类的方法名，蛋疼；或者改成如下方式。</code></pre><ol start="3"><li><pre><code>type GoLevelDB struct {    db *leveldb.DB}</code></pre><p>和第 2 种的区别就是把 is-a 改为 has-a，也不用担心方法重名的问题。不过我私以为若 Go 支持重载，第 2 种方式会好一点，至少不会嵌套太多层。</p></li></ol><p><strong>服务端</strong></p><p>abci 定义了如下接口：</p><pre><code>type Application interface {    // Info/Query Connection    Info(RequestInfo) ResponseInfo                // Return application info    SetOption(RequestSetOption) ResponseSetOption // Set application option    Query(RequestQuery) ResponseQuery             // Query for state    // Mempool Connection    CheckTx(tx []byte) ResponseCheckTx // Validate a tx for the mempool    // Consensus Connection    InitChain(RequestInitChain) ResponseInitChain    // Initialize blockchain with validators and other info from TendermintCore    BeginBlock(RequestBeginBlock) ResponseBeginBlock // Signals the beginning of a block    DeliverTx(tx []byte) ResponseDeliverTx           // Deliver a tx for full processing    EndBlock(RequestEndBlock) ResponseEndBlock       // Signals the end of a block, returns changes to the validator set    Commit() ResponseCommit                          // Commit the state and return the application Merkle root hash}</code></pre><p>很明显，后面几个方法参与了区块链状态的更迭，我们就来捋捋交易从客户端提交到最终上链的过程（不精确）：</p><ol><li>节点 a 的客户端发起一笔交易 tx；</li><li>节点 a 服务端调用 CheckTx 方法校验 tx 是否合法，若非法则丢弃，当做什么事都没发生过；</li><li>若合法，则将 tx 加入到本地 mempool 中，并向其它节点广播 tx；</li><li>其它节点接收到 tx，同样执行 2-3 步骤；</li><li>某轮决议开始，提议者搜集 mempool 中的 txs，并发起投票，达成共识后，各节点调用 BeginBlock 开始将它们打包；</li><li>调用 DeliverTx 执行每笔交易并将其记录到区块中（一笔交易执行一次 DeliverTx）；</li><li>调用 EndBlock 表示打包完成；</li><li>发起共识决议，提议者将新区块广播给其它验证者；（共识决议在第 5 步完成）</li><li>其它验证者接收到区块后，调用 DeliverTx 执行每笔交易并校验结果，若没问题则广播 commit 请求（预提交）和新区块；</li><li>若节点收到超过 2/3 验证者的 commit 请求，调用 Commit 方法，更新整个应用状态。</li></ol><p>假如将要打包的 tx 缓存起来，我们就可以在 DeliverTx、EndBlock、Commit 三个方法中选择其一实际执行 tx，但是一般来说，交易执行都是放在 DeliverTx，比较符合语义。EndBlock 用于更新共识参数和 Val 集合，Commit 用于更新整个应用状态（apphash），需要注意的是，本次提交的 apphash 若与上次提交的不同，则会继续产生新的区块（不管有没有新交易，就算设置 consensus.create_empty_blocks=false，tendermint 也会产生空区块，可参看 <a href="https://github.com/cosmos/ethermint/issues/308" target="_blank" rel="noopener">Enable no empty blocks #308</a> 。），这似乎是 tendermint 的有意设计，但不知为何。</p><p>另 Query 方法接收的 RequestQuery 类型参数有 Path 和 Data 两个字段，Path 是 string 类型，Data 是 []byte，应该是对应于 Http 的 get、post。示例代码中我是通过正则表达式解析 Path 查询各类数据，其实若是复杂查询 / 结构化查询，还是 Data 字段比较实用。</p><p><em>正则表达式的所谓零宽断言：只匹配位置，而不消费字符。下面举个例子。如 \b\w<em>q[^u]\w</em>\b，它能匹配 “Iraq,Benq”。因为[^u] 总是匹配一个字符，所以如果 q 是单词的最后一个字符的话，后面的 [^u] 将会匹配 q 后面的单词分隔符 (可能是空格，或者是句号或其它的什么)，接着后面的 \ w+\b 将会匹配下一个单词，于是 \ b\w<em>q[^u]\w</em>\b 就能匹配整个 Iraq fighting。如果在这个例子中，我们只想匹配到 Iraq，那么可以采用零宽负向先行断言(?!exp) 的方式，\b\w<em>q(?!u)\w</em>\b，它将不会消费 Iraq 后面的空格或逗号等字符，因此 \ w * 也不会匹配到下一个单词。参看 <a href="https://www.cnblogs.com/sunny3096/p/7201403.html" target="_blank" rel="noopener">【详细】正则表达式 30 分钟入门教程</a> 之位置指定和后向位置指定部分。</em></p><p><strong>客户端</strong></p><p>demo 采用命令行终端，基于 cobra 库。</p><pre><code> var rootCmd = &amp;cobra.Command{     Use:   &quot;dbcli&quot;,     //throw:丢；salvage:捞；reply:回应。 ValidArgs要有定义Run[E]，并与Args: cobra.OnlyValidArgs结合才起作用，表示参数值只能是预设值      //ValidArgs: []string{&quot;throw&quot;, &quot;salvage&quot;, &quot;reply&quot;, &quot;bbalj&quot;},      //Args主要是用来校验参数的      //Args: cobra.OnlyValidArgs, //cobra.ExactArgs(0),      // RunE: func(cmd *cobra.Command, args []string) error { //args并不包含flag；os.Args是包含flag的     // }, } func main() {     if err := rootCmd.Execute(); err != nil {         fmt.Println(err)         os.Exit(-1)     } }</code></pre><p>原本我想实现交互模式（类似 mysql&gt;），但 cobra 似乎没有提供相关方法，我们只好自己想办法，需要注意的是需要自解析用户输入，比如用户输入有空格，该空格是分隔参数还是参数内部的，要做区分。原本打算参考 cobra 解析命令行的源码，发现实际解析使用的是 spf13/pflag 库，而 pflag 只是加强了 go 标准库 flag，而 flag 库也并没有涉及到参数值本身的具体解析，这部分工作依靠的是 oa 库，主要是 oa.Args 属性，它依赖更底层的代码。</p><pre><code>// 摘自go/src/os/proc.go// Args hold the command-line arguments, starting with the program name.var Args []stringfunc init() {    if runtime.GOOS == &quot;windows&quot; {        // Initialized in exec_windows.go.        return    }    Args = runtime_args()}func runtime_args() []string // in package runtime</code></pre><p>如注释所示，windows 下是在 exec_windows.go 中实现，其它操作系统的实现没找到，应该是使用其它语言编写或直接调用的系统 api。进 exec_windows.go 中，发现关键函数 readNextArg：</p><pre><code> // readNextArg splits command line string cmd into next // argument and command line remainder. func readNextArg(cmd string) (arg []byte, rest string) {     var b []byte     var inquote bool     var nslash int     for ; len(cmd) &gt; 0; cmd = cmd[1:] {         c := cmd[0]         switch c {         case &#39; &#39;, &#39;\t&#39;:             if !inquote {                 return appendBSBytes(b, nslash), cmd[1:]             }         case &#39;&quot;&#39;:             b = appendBSBytes(b, nslash/2)             if nslash%2 == 0 {                 // use &quot;Prior to 2008&quot; rule from                 // http://daviddeley.com/autohotkey/parameters/parameters.htm                 // section 5.2 to deal with double double quotes                 if inquote &amp;&amp; len(cmd) &gt; 1 &amp;&amp; cmd[1] == &#39;&quot;&#39; {                     b = append(b, c)                     cmd = cmd[1:]                 }                 inquote = !inquote             } else {                 b = append(b, c)             }             nslash = 0             continue         case &#39;\\&#39;:             nslash++             continue         }         b = appendBSBytes(b, nslash)         nslash = 0         b = append(b, c)     }     return appendBSBytes(b, nslash), &quot;&quot; }</code></pre><p>其中对双引号做了处理，注释中还提供了一个网址 <a href="http://daviddeley.com/autohotkey/parameters/parameters.htm" target="_blank" rel="noopener">How Command Line Parameters Are Parsed</a>，应该是关于这方面的算法说明，日后再看。</p><p><strong>序列化</strong></p><p>当我们在说序列化的时候，我们在说什么。序列化说白了就是数据转化，或者说一一对应的映射关系。就内存场景来说，一个对象序列化为另一个对象，本质上它们都一样，都是存储在内存中的 0、1 序列，只是同一个东西不同的数据表达。比如将一个数值序列化（或者说转化）成字符串类型，或者将数值 int32 转为数值 int8，那么内存中的存储空间和存储数据都不会一样，字符串还要看用的什么编码。再如我们将一个对象序列化为 byte[]，不同的方案会产生不同的结果。比如使用 C 指针将物理数据直接映射出来，或者以 json 方式序列化，或者 protobuf 序列化，会产生不同的 byte[]；反之亦然。</p><p>不管是 json 编码还是二进制编码，物理上存储的都是二进制，json 编码包含于二进制编码，我们可以根据需要自定义二进制编码，一般是为了减少存储占用的空间。比如 json 编码，对 1、2 等数值类型是按字符串格式编码（如 utf8 格式，1 编码的就是 0x31,12 占两个字节 0x310x32），而我们自定义二进制，完全可以把 12 存储在一个字节里面，该字节值就是数值本身；就算不是数值，而是字符串本身编码，我们也可以在 utf8 编码后再压缩，类似 gzip。</p><p>go 中的序列化方式，可参看 <a href="https://blog.csdn.net/fengfengdiandia/article/details/79986237" target="_blank" rel="noopener">Golang 序列化方式及对比</a>，但是文中 gob 的测试代码其实可以改良下，将 enc/dec 两个变量移到循环外，如此可在循环内复用，这将发挥 gob 上下文的优势。</p><p>protobuf 的变长编码针对的是数值类型，so 应该只对数值字段多的类型有压缩的意义。</p><p>go 对字符串是 utf8 编码，基本不用担心中文乱码问题。</p><p><strong>vscode-go 开发环境</strong></p><p>在国内，搭建 Go 开发环境都不会太顺利，下面我就说说在 vscode 中搭建环境可能会遇到的问题和解决方法。</p><p>Go 开发环境需要 vscode 安装一些插件，而项目中也有引用的类库，这两者都可能涉及到相关站点在墙外的情况，而我们也要分别设置代理。首先，给 vscode 本身设置代理，使得安装插件没有问题；其次，在命令行窗口设置 http_proxy，使得 dep 顺利进行。也可以在 vscode 终端窗口设置 http_proxy（vscode 的终端就是个命令行交互环境，使用的还是操作系统的 shell，本质上独立于 vscode），但博主发现似乎并不起作用。</p><p><em>在代理什么都设置好后，vscode 安装插件时仍可能遇到问题，比如文件中已经存在的 golang.org\x\tools 目录关联的 git 源码网址不是插件要求的源码网址，原因可能是之前手动到 github 里下载的 tools 源码，将 tools 目录移除重新跑一遍安装插件的步骤即可。</em></p><p>安装 goimports 时可能会 timeout 等错误，参考 <a href="http://www.cnblogs.com/sysnap/p/7049663.html" target="_blank" rel="noopener">安装 goimports</a> 解决。</p><p>项目方面，具体到我们这个 demo，遵照 tendermint 官方文档，make get_tools。我是 windows10 系统，使用 bash 命令进入到自带的 Ubuntu 子系统，就可以使用内置的 make 了。需要注意的是，若设置了系统变量 GOPATH，且是以分号分隔的多个文件夹，那么切换到 Ubuntu 后，由于 linux 系统是按冒号分隔的，所以它会把分号当做文件夹名的一部分，导致自动创建一些奇怪目录。如果是其它 windows 系统，可以安装 mingw，定位到安装目录的 bin 目录下，就可以使用 mingw-make 操作了（可以将 mingw-make 重命名为 make），可能会报错：</p><pre><code>process_begin: CreateProcess(NULL, env bash F:\Document\code\tendermint\tendermint\scripts\get_tools.sh, ...) failed.make (e=2): 系统找不到指定的文件。</code></pre><p>如果不是 get_tools.sh 的路径问题，那就应该是 bash 冲突了（比如系统中安装了 git，同时把 git 目录也配置到 PATH 下，实际定位的可能就是 git 的 bash 了）。</p><p>注意 tendermint 所需的最低 Go 版本。</p><p>我们要严格遵循 Go 的目录规范，若将代码直接置于 src \ 目录下，则执行 dep 相关操作时，会抛出 “root project import: dep does not currently support using GOPATH/src as the project root” 错误。需要在 src \ 下再建一个目录，把代码拷进这个子目录再执行 dep。Go 遵循约定大于配置的原则，它在项目中引入所有依赖类库的代码，而这些类库也是放置于 src 目录下，所以需要按子目录分开。另关于依赖项搜寻 <a href="https://github.com/golang/dep/pull/313#issuecomment-285918383" target="_blank" rel="noopener">Support vendor directory as $GOPATH/src/vendor #313</a> 应该有参考价值，另可参看 <a href="https://github.com/golang/dep/issues/148" target="_blank" rel="noopener">dep init fails if in not in $GOPATH[…]/src/{somedir..} #148</a>。</p><p>dep 似乎会将 GOPATH\src 下的依赖也复制到 vendor 下，感觉是不是没这必要。</p><p>经验：最好在项目刚开始搭建就 dep init，否则在代码敲了一个阶段后，已经 import 了多个外部依赖，当这时候再 dep init，如果出现错误，将不会生成 Gopkg.toml，如果是因为版本问题导致的错误，你都没办法通过编辑 Gopkg.toml 的方式解决。比如我就遇到这种情况，dep init -gopath， -gopath 表示先去本地 GOPATH 目录找依赖库，找不到再去网上拉取，结果我的本地库版本不是 master 分支，而貌似 dep 默认的就是 master，导致 “v0.30.2: Could not introduce github.com/tendermint/tendermint@v0.30.2, as it is not allowed by constraint master from project tuoxie/driftbottle.” 这样的错误提示（dep 也是一根筋，它会把这个库的所有 release 版本都比对一遍看满不满足 constraint）。此时也不是没办法，我们可以把入口函数 main 所在文件整个注释掉，这样 dep 就不会遍历代码文件，但仍然会生成 Gopkg.toml，这个时候就可以手动编辑约束版本号了。</p><p>go install 不会把 vendor 目录下的所有包无脑打包进 exe 文件，而是会根据实际依赖打包，这样也使得我们可以多个 [子] 项目使用同一个 vendor，减小磁盘占用和复用已下载的依赖包，而不必担心 exe 文件过大的问题。</p><p>目前 vscode 调试 go 尚不能支持交互模式的命令行调试，没有如 python 那样可以在 launch.json 设置 console 属性 [为 externalTerminal]。</p><p><strong>其它</strong></p><p>作为区块链最广泛应用的数字货币已经不再像不久以前一样能够随意撩拨投机者的神经，但这项技术在其它更实用的领域或许仍值得期待。比如区块链的共识机制、区块时间戳、防篡改特性，似乎天生是为知识产权保护打造的，然而迄今为止市面上尚未出现让人眼前一亮的产品。前段时间看到一则新闻，说百度上线了一个保护图片版权的区块链项目 “图腾”，有兴趣的同学可以去了解下。如果我要实现类似的知识产权链，会考虑文件相似度判别、[使用代币] 支付版权费及支付策略（买断 or 按次付款等）等等，交易媒介和交易标的都在链上，形成闭环。链上闭环可不受外部实体困扰，以区块链二代的明星特性 “智能合约” 为例，一旦与外部有所关联，就无法保证合约的事务完整性，可参看我之前的<a href="https://www.cnblogs.com/newton/p/9443006.html#znhyza" target="_blank" rel="noopener">观点</a>。</p><p>Tendermint 里有很多 ethereum 的影子，比如 gas、db 的封装等，部分思路和代码应该是参考了 ethereum 的实现。</p><p><strong>ethereum（以太坊）相关概念：</strong></p><p>MPT：即 Merkle Patricia Tree，是 Merkle Tree 和 Patricia Tree 结合的产物。Patricia Tree 又是 Trie Tree 的一种变化。参考资料：<a href="https://blog.csdn.net/wsyw126/article/details/61416055" target="_blank" rel="noopener">Trie 原理以及应用于搜索提示</a>，<a href="https://blog.csdn.net/itleaks/article/details/79992072" target="_blank" rel="noopener">以太坊 MPT 原理，你最值得看的一篇</a>。这两篇偏向于原理，若要了解具体细节，可看 <a href="https://ethfans.org/posts/merkle-patricia-tree-in-detail" target="_blank" rel="noopener">干货 | Merkle Patricia Tree 详解</a>。</p><p>叔区块</p><p>gas：一直很好奇以太坊是怎么做到计算实际使用 gas 量的，特别是有控制跳转语句的时候，最可靠的方式是实际运行时实时计算 gas，那这个应该是由 EVM 实现的。具体可看 <a href="https://blog.csdn.net/weixin_41545330/article/details/79474689" target="_blank" rel="noopener">以太坊虚拟机及交易的执行</a>，<a href="https://blog.csdn.net/mongo_node/article/details/80216079" target="_blank" rel="noopener">以太坊智能合约虚拟机 (EVM) 原理与实现</a>。</p><p>数据结构与存储方式：<a href="https://blog.csdn.net/itleaks/article/details/80094294" target="_blank" rel="noopener">以太坊源码情景分析之数据结构</a>，<a href="https://blog.csdn.net/teaspring/article/details/75390210" target="_blank" rel="noopener">[以太坊源代码分析] II. 数据的呈现和组织，缓存和更新</a></p><p><strong>个人认为区块链目前普遍存在的问题：</strong></p><ul><li>升级困难（侧链？）</li><li>维护困难（当单节点故障时，只能依靠该节点自身能力处理，对于普通用户来说，无疑是棘手的）</li><li>随着时间的推移，数据量会变得越来越大，全节点将相应变少，最终形成某种意义上的中心化网络</li></ul><p>更多资料：</p><p><a href="https://www.jianshu.com/p/bbf956f3ffaa" target="_blank" rel="noopener">以太坊源码深入分析（7）– 以太坊 Downloader 源码分析</a></p><p>转载请注明本文出处：<a href="https://www.cnblogs.com/newton/p/9611340.html" target="_blank" rel="noopener" title="view: 基于Tendermint的区块链漂流瓶简单实现">https://www.cnblogs.com/newton/p/9611340.html</a></p>]]></content>
      
      
      <categories>
          
          <category> 区块链 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tendermint </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深入剖析区块链的共识算法 Raft &amp; PBFT</title>
      <link href="/2020/02/29/raft-pbft-algorithm/"/>
      <url>/2020/02/29/raft-pbft-algorithm/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文由 <a href="http://ksria.com/simpread/" target="_blank" rel="noopener">简悦 SimpRead</a> 转码， 原文地址 <a href="https://www.cnblogs.com/davidwang456/articles/9001331.html" target="_blank" rel="noopener">https://www.cnblogs.com/davidwang456/articles/9001331.html</a></p></blockquote><p>来自公众号：高可用架构</p><p>区块链技术中，共识算法是其中核心的一个组成部分。首先我们来思考一个问题：什么是共识？对于现实世界，共识就是一群人对一件或者多件事情达成一致的看法或者协议。那么在计算机世界当中，共识是什么呢？</p><p>我的理解包含两个层面，第一个层面是点的层面，即多个节点对某个数据达成一致共识。第二个层面是线的层面，即多个节点对多个数据的顺序达成一致共识。这里的节点可以是任意的计算机设备，比如 pc 电脑，笔记本，手机，路由器等，这里的数据可以是交易数据，状态数据等。其中对数据顺序达成一致共识是很多共识算法要解决的本质问题。</p><p>常见的共识算法都有哪些呢？现阶段的共识算法主要可以分成三大类：公链，联盟链和私链。下面描述这三种类别的特征。</p><p>私链：私链的共识算法即区块链这个概念还没普及时的传统分布式系统里的共识算法，比如 zookeeper 的 zab 协议，就是类 paxos 算法的一种。私链的适用环境一般是不考虑集群中存在作恶节点，只考虑因为系统或者网络原因导致的故障节点。</p><p>联盟链：联盟链中，经典的代表项目是 Hyperledger 组织下的 Fabric 项目，Fabric0.6 版本使用的就是 pbft 算法。联盟链的适用环境除了需要考虑集群中存在故障节点，还需要考虑集群中存在作恶节点。对于联盟链，每个新加入的节点都是需要验证和审核的。</p><p>公链：公链不仅需要考虑网络中存在故障节点，还需要考虑作恶节点，这一点和联盟链是类似的。和联盟链最大的区别就是，公链中的节点可以很自由的加入或者退出，不需要严格的验证和审核。</p><p>本文接下来将会主要阐述私链的 raft 算法和联盟链的 pbft 算法，以及它们的区别和对比。</p><p><img src="/2020/02/29/raft-pbft-algorithm/486074-20180507102612727-862608830.png" alt></p><p><strong>【一．raft 算法】</strong></p><p>因为网上已经有大量文章对 raft 算法进行过详细的介绍，因此这部分只会简单的阐述算法的基本原理和流程。raft 算法包含三种角色，分别是：跟随者（follower），候选人（candidate）和领导者（leader）。集群中的一个节点在某一时刻只能是这三种状态的其中一种，这三种角色是可以随着时间和条件的变化而互相转换的。</p><p>raft 算法主要有两个过程：一个过程是领导者选举，另一个过程是日志复制，其中日志复制过程会分记录日志和提交数据两个阶段。raft 算法支持最大的容错故障节点是（N-1）/2，其中 N 为 集群中总的节点数量。</p><p>国外有一个动画介绍 raft 算法介绍的很透彻，链接地址在这里 [1]。这个动画主要包含三部分内容，第一部分介绍简单版的领导者选举和日志复制的过程，第二部分内容介绍详细版的领导者选举和日志复制的过程，第三部分内容介绍的是如果遇到网络分区（脑裂），raft 算法是如何恢复网络一致的。有兴趣的朋友可以结合这个动画来更好的理解 raft 算法。</p><p><strong>【二．pbft 算法】</strong></p><p>pbft 算法的提出主要是为了解决拜占庭将军问题。什么是拜占庭将军问题呢？拜占庭位于如今的土耳其的伊斯坦布尔，是古代东罗马帝国的首都。拜占庭罗马帝国国土辽阔，为了达到防御目的，每块封地都驻扎一支由将军统领的军队，每个军队都分隔很远，将军与将军之间只能靠信差传递消息。 在战争的时候，拜占庭军队内所有将军必需达成一致的共识，决定是否有赢的机会才去攻打敌人的阵营。但是，在军队内有可能存有叛徒和敌军的间谍，左右将军们的决定影响将军们达成一致共识。在已知有将军是叛徒的情况下，其余忠诚的将军如何达成一致协议的问题，这就是拜占庭将军问题。 </p><p>要让这个问题有解，有一个十分重要的前提，那就是信道必须是可靠的。如果信道不能保证可靠，那么拜占庭问题无解。关于信道可靠问题，会引出两军问题。两军问题的结论是，在一个不可靠的通信链路上试图通过通信以达成一致是基本不可能或者十分困难的。</p><p>那么如果在信道可靠的情况下，要如何解这个问题呢？拜占庭将军问题其实有很多种解法，接下来先介绍两位大牛，这两位大牛都在解决拜占庭问题上做出了突出的贡献。</p><p><img src="/2020/02/29/raft-pbft-algorithm/486074-20180507102638832-906668262.png" alt></p><p>如上图所示，拜占庭将军问题最早是由 Leslie Lamport 与另外两人在 1982 年发表的论文《The Byzantine Generals Problem 》提出的， 他证明了在将军总数大于 3f ，背叛者为 f 或者更少时，忠诚的将军可以达成命令上的一致，即 3f+1&lt;=n。算法复杂度为 o（n^(f+1))。而 Miguel Castro (卡斯特罗) 和 Barbara Liskov（利斯科夫）在 1999 年发表的论文《Practical Byzantine Fault Tolerance》中首次提出 pbft 算法，该算法容错数量也满足 3f+1&lt;=n, 算法复杂度为 o（n^2）。</p><p>网上关于 pbft 的算法介绍基本上是基于 liskov 在 1999 年发表的论文《Practical Byzantine Fault Tolerance》来进行解释的。当前网上介绍 pbft 的中文文章不算太多，基本上只有那几篇，并且感觉有些关键点解释得不够清晰，因此接下来会详细描述下 pbft 算法的过程和原理。</p><p><strong>2.1 推论：raft 算法的 2f+1&lt;=n 和 pbft 的 3f+1&lt;=n</strong></p><p>首先我们先来思考一个问题，为什么 pbft 算法的最大容错节点数量是（n-1）/3，而 raft 算法的最大容错节点数量是（n-1）/2？</p><p>对于 raft 算法，raft 算法的的容错只支持容错故障节点，不支持容错作恶节点。什么是故障节点呢？就是节点因为系统繁忙、宕机或者网络问题等其它异常情况导致的无响应，出现这种情况的节点就是故障节点。那什么是作恶节点呢？作恶节点除了可以故意对集群的其它节点的请求无响应之外，还可以故意发送错误的数据，或者给不同的其它节点发送不同的数据，使整个集群的节点最终无法达成共识，这种节点就是作恶节点。</p><p>raft 算法只支持容错故障节点，假设集群总节点数为 n，故障节点为 f，根据小数服从多数的原则，集群里正常节点只需要比 f 个节点再多一个节点，即 f+1 个节点，正确节点的数量就会比故障节点数量多，那么集群就能达成共识。因此 raft 算法支持的最大容错节点数量是（n-1）/2。</p><p>对于 pbft 算法，因为 pbft 算法的除了需要支持容错故障节点之外，还需要支持容错作恶节点。假设集群节点数为 N，有问题的节点为 f。有问题的节点中，可以既是故障节点，也可以是作恶节点，或者只是故障节点或者只是作恶节点。那么会产生以下两种极端情况：</p><p>第一种情况，f 个有问题节点既是故障节点，又是作恶节点，那么根据小数服从多数的原则，集群里正常节点只需要比 f 个节点再多一个节点，即 f+1 个节点，确节点的数量就会比故障节点数量多，那么集群就能达成共识。也就是说这种情况支持的最大容错节点数量是（n-1）/2。</p><p>第二种情况，故障节点和作恶节点都是不同的节点。那么就会有 f 个问题节点和 f 个故障节点，当发现节点是问题节点后，会被集群排除在外，剩下 f 个故障节点，那么根据小数服从多数的原则，集群里正常节点只需要比 f 个节点再多一个节点，即 f+1 个节点，确节点的数量就会比故障节点数量多，那么集群就能达成共识。所以，所有类型的节点数量加起来就是 f+1 个正确节点，f 个故障节点和 f 个问题节点，即 3f+1=n。</p><p>结合上述两种情况，因此 pbft 算法支持的最大容错节点数量是（n-1）/3。下图展示了论文里证明 pbft 算法为什么 3f+1&lt;=n 的一段原文，以及根据原文提到的两种情况对应的示意图。</p><p><img src="/2020/02/29/raft-pbft-algorithm/486074-20180507102826822-64890543.png" alt></p><p>3f+1&lt;=n 这个结论在 pbft 算法的流程中会大量使用到，因此在介绍 pbft 算法流程前先解释下这个推论。</p><p><strong>2.2 算法基本流程</strong></p><p>pbft 算法的基本流程主要有以下四步：</p><ol><li><p>客户端发送请求给主节点</p></li><li><p>主节点广播请求给其它节点，节点执行 pbft 算法的三阶段共识流程。</p></li><li><p>节点处理完三阶段流程后，返回消息给客户端。</p></li><li><p>客户端收到来自 f+1 个节点的相同消息后，代表共识已经正确完成。</p></li></ol><p>为什么收到 f+1 个节点的相同消息后就代表共识已经正确完成？从上一小节的推导里可知，无论是最好的情况还是最坏的情况，如果客户端收到 f+1 个节点的相同消息，那么就代表有足够多的正确节点已全部达成共识并处理完毕了。</p><p><strong>2.3 算法核心三阶段流程</strong></p><p>   下面介绍 pbft 算法的核心三阶段流程，如下图所示：</p><p><img src="/2020/02/29/raft-pbft-algorithm/486074-20180507102853695-64359151.png" alt></p><p><img src="/2020/02/29/raft-pbft-algorithm/640.png" alt></p><p> 算法的核心三个阶段分别是 pre-prepare 阶段（预准备阶段），prepare 阶段（准备阶段），commit 阶段（提交阶段）。图中的 C 代表客户端，0，1，2，3 代表节点的编号，打叉的 3 代表可能是故障节点或者是问题节点，这里表现的行为就是对其它节点的请求无响应。0 是主节点。整个过程大致是：</p><p>首先，客户端向主节点发起请求，主节点 0 收到客户端请求，会向其它节点发送 pre-prepare 消息，其它节点就收到了 pre-prepare 消息，就开始了这个核心三阶段共识过程了。</p><p>Pre-prepare 阶段：节点收到 pre-prepare 消息后，会有两种选择，一种是接受，一种是不接受。什么时候才不接受主节点发来的 pre-prepare 消息呢？一种典型的情况就是如果一个节点接到了一条 pre-pre 消息，消息里的 v 和 n 在之前收到里的消息是曾经出现过的，但是 d 和 m 却和之前的消息不一致，或者请求编号不在高低水位之间（高低水位的概念在 2.4 节会进行解释），这时候就会拒绝请求。拒绝的逻辑就是主节点不会发送两条具有相同的 v 和 n，但 d 和 m 却不同的消息。</p><p>Prepare 阶段：节点同意请求后会向其它节点发送 prepare 消息。这里要注意一点，同一时刻不是只有一个节点在进行这个过程，可能有 n 个节点也在进行这个过程。因此节点是有可能收到其它节点发送的 prepare 消息的。在一定时间范围内，如果收到超过 2f 个不同节点的 prepare 消息，就代表 prepare 阶段已经完成。</p><p>Commit 阶段：于是进入 commit 阶段。向其它节点广播 commit 消息，同理，这个过程可能是有 n 个节点也在进行的。因此可能会收到其它节点发过来的 commit 消息，当收到 2f+1 个 commit 消息后（包括自己），代表大多数节点已经进入 commit 阶段，这一阶段已经达成共识，于是节点就会执行请求，写入数据。</p><p> 处理完毕后，节点会返回消息给客户端，这就是 pbft 算法的全部流程。</p><p>为了更清晰的展现这个过程和一些细节，下面以流程图来表示这个过程。</p><p><img src="/2020/02/29/raft-pbft-algorithm/486074-20180507102718422-1141825881.png" alt></p><p>注解：</p><p>V：当前视图的编号。视图的编号是什么意思呢？比如当前主节点为 A，视图编号为 1，如果主节点换成 B，那么视图编号就为 2. 这个概念和 raft 的 term 任期是很类似的。</p><p>N：当前请求的编号。主节点收到客户端的每个请求都以一个编号来标记。</p><p>M：消息的内容</p><p>d 或 D（m）：消息内容的摘要</p><p> i： 节点的编号</p><p><strong>2.4 checkpoint、stable **checkpoint</strong> 和高低水位**</p><p>什么是 checkpoint 呢？checkpoint 就是当前节点处理的最新请求序号。前文已经提到主节点收到请求是会给请求记录编号的。比如一个节点正在共识的一个请求编号是 101，那么对于这个节点，它的 checkpoint 就是 101.</p><p>那什么是 stable checkpoint（稳定检查点）呢？stable checkpoint 就是大部分节点（2f+1）已经共识完成的最大请求序号。比如系统有 4 个节点，三个节点都已经共识完了的请求编号是 213. 那么这个 213 就是 stable checkpoint 了。</p><p>那设置这个 stable checkpoint 有什么作用呢？最大的目的就是减少内存的占用。因为每个节点应该记录下之前曾经共识过什么请求，但如果一直记录下去，数据会越来越大，所以应该有一个机制来实现对数据的删除。那怎么删呢？很简单，比如现在的稳定检查点是 213，那么代表 213 号之前的记录已经共识过的了，所以之前的记录就可以删掉了。</p><p>那什么是高低水位呢？下面以一个示意图来进行解释。</p><p><img src="/2020/02/29/raft-pbft-algorithm/486074-20180507102918856-832514733.png" alt></p><p>图中 A 节点的当前请求编号是 1039，即 checkpoint 为 1039，B 节点的 checkpoint 为 1133. 当前系统 stable checkpoint 为 1034. 那么 1034 这个编号就是低水位，而高水位 H = 低水位 h+L，其中 L 是可以设定的数值。因此图中系统的高水位为 1034+100=1134。</p><p>举个例子：如果 B 当前的 checkpoint 已经为 1034，而 A 的 checkpoint 还是 1039，假如有新请求给 B 处理时，B 会选择等待，等到 A 节点也处理到和 B 差不多的请求编号时，比如 A 也处理到 1112 了，这时会有一个机制更新所有节点的 stabel checkpoint ，比如可以把 stabel checkpoint 设置成 1100，于是 B 又可以处理新的请求了，如果 L 保持 100 不变，这时的高水位就会变成 1100+100=1200 了。</p><p><strong>2.5 ViewChange（视图更改）事件</strong></p><p>当主节点挂了（超时无响应）或者从节点集体认为主节点是问题节点时，就会触发 ViewChange 事件，ViewChange 完成后，视图编号将会加 1。</p><p>下图展示 ViewChange 的三个阶段流程。</p><p><img src="/2020/02/29/raft-pbft-algorithm/486074-20180507102944761-1054895183.png" alt></p><p>如图所示，viewchange 会有三个阶段，分别是 view-change，view-change-ack 和 new-view 阶段。从节点认为主节点有问题时，会向其它节点发送 view-change 消息，当前存活的节点编号最小的节点将成为新的主节点。当新的主节点收到 2f 个其它节点的 view-change 消息，则证明有足够多人的节点认为主节点有问题，于是就会向其它节点广播</p><p>New-view 消息。注意：从节点不会发起 new-view 事件。对于主节点，发送 new-view 消息后会继续执行上个视图未处理完的请求，从 pre-prepare 阶段开始。其它节点验证 new-view 消息通过后，就会处理主节点发来的 pre-prepare 消息，这时执行的过程就是前面描述的 pbft 过程。到这时，正式进入 v+1（视图编号加 1）的时代了。</p><p>为了更清晰的展现 ViewChange 这个过程和一些细节，下面以流程图来表示这个过程。</p><p><img src="/2020/02/29/raft-pbft-algorithm/486074-20180507102957016-2140471289.png" alt></p><p>上图里红色字体部分的 O 集合会包含哪些 pre-prepare 消息呢？假设 O 集合里消息的编号范围：（min～max），则 Min 为 V 集合最小的 stable checkpoint，Max 为 V 集合中最大序号的 prepare 消息。最后一步执行 O 集合里的 pre-preapare 消息，每条消息会有两种情况: 如果 max-min&gt;0, 则产生消息 &lt;pre-prepare,v+1,n,d&gt; ；如果 max-min=0，则产生消息 &lt; pre-prepare,v+1,n,d(null)&gt;。</p><p><strong>【三．raft 和 pbft 的对比】</strong></p><p>下图列出了 raft 算法和 pbft 算法在适用环境，通信复杂度，最大容错节点数和流程上的对比。</p><p><img src="/2020/02/29/raft-pbft-algorithm/640.jfif" alt></p><p>关于两个算法的适用环境和最大容错节点数，前文已经做过阐述，这里不再细说。而对于算法通信复杂度，为什么 raft 是 o（n），而 pbft 是 o（n^2）呢？这里主要考虑算法的共识过程。</p><p>对于 raft 算法，核心共识过程是日志复制这个过程，这个过程分两个阶段，一个是日志记录，一个是提交数据。两个过程都只需要领导者发送消息给跟随者节点，跟随者节点返回消息给领导者节点即可完成，跟随者节点之间是无需沟通的。所以如果集群总节点数为 n，对于日志记录阶段，通信次数为 n-1，对于提交数据阶段，通信次数也为 n-1，总通信次数为 2n-2，因此 raft 算法复杂度为 O（n）。</p><p>对于 pbft 算法，核心过程有三个阶段，分别是 pre-prepare（预准备）阶段，prepare（准备）阶段和 commit（提交）阶段。对于 pre-prepare 阶段，主节点广播 pre-prepare 消息给其它节点即可，因此通信次数为 n-1；对于 prepare 阶段，每个节点如果同意请求后，都需要向其它节点再 广播 parepare 消息，所以总的通信次数为 n<em>（n-1），即 n^2-n；对于 commit 阶段，每个节点如果达到 prepared 状态后，都需要向其它节点广播 commit 消息，所以总的通信次数也为 n</em>（n-1），即 n^2-n。所以总通信次数为（n-1）+（n^2-n）+（n^2-n），即 2n^2-n-1，因此 pbft 算法复杂度为 O（n^2）。</p><p>流程的对比上，对于 leader 选举这块，raft 算法本质是谁快谁当选，而 pbft 算法是按编号依次轮流做主节点。对于共识过程和重选 leader 机制这块，为了更形象的描述这两个算法，接下来会把 raft 和 pbft 的共识过程比喻成一个团队是如何执行命令的过程，从这个角度去理解 raft 算法和 pbft 的区别。</p><p>一个团队一定会有一个老大和普通成员。对于 raft 算法，共识过程就是：只要老大还没挂，老大说什么，我们（团队普通成员）就做什么，坚决执行。那什么时候重新老大呢？只有当老大挂了才重选老大，不然生是老大的人，死是老大的鬼。</p><p>对于 pbft 算法，共识过程就是：老大向我发送命令时，当我认为老大的命令是有问题时，我会拒绝执行。就算我认为老大的命令是对的，我还会问下团队的其它成员老大的命令是否是对的，只有大多数人（2f+1）都认为老大的命令是对的时候，我才会去执行命令。那什么时候重选老大呢？老大挂了当然要重选，如果大多数人都认为老大不称职或者有问题时，我们也会重新选择老大。</p><p><strong>【四．结语】</strong></p><p>raft 算法和 pbft 算法是私链和联盟链中经典的共识算法，本文主要介绍了 raft 和 pbft 算法的流程和区别。raft 和 pbft 算法有两点根本区别：</p><ol><li><p>raft 算法从节点不会拒绝主节点的请求，而 pbft 算法从节点在某些情况下会拒绝主节点的请求 ;</p></li><li><p>raft 算法只能容错故障节点，并且最大容错节点数为（n-1）/2，而 pbft 算法能容错故障节点和作恶节点，最大容错节点数为（n-1）/3。</p></li></ol><p>本文没有涉及算法正确性和收敛性的证明，从算法设计的角度来讲，是需要做这两方面工作的。</p><p><strong>文中链接：</strong></p><p>[1]<a href="http://thesecretlivesofdata.com/raft/" target="_blank" rel="noopener">http://thesecretlivesofdata.com/raft/</a></p>]]></content>
      
      
      <categories>
          
          <category> 区块链 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PBFT </tag>
            
            <tag> RAFT </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PBFT实用拜占庭容错算法深入详解</title>
      <link href="/2020/02/29/pbft-algorithm/"/>
      <url>/2020/02/29/pbft-algorithm/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文由 <a href="http://ksria.com/simpread/" target="_blank" rel="noopener">简悦 SimpRead</a> 转码， 原文地址 <a href="https://blog.csdn.net/TurkeyCock/article/details/81672759?utm_source=tuicool&amp;utm_medium=referral" target="_blank" rel="noopener">https://blog.csdn.net/TurkeyCock/article/details/81672759?utm_source=tuicool&amp;utm_medium=referral</a></p></blockquote><p>PBFT 即实用拜占庭容错算法，由 Miguel Castro 和 Barbara Liskov 在 1999 年提出，可以在作恶节点少于三分之一的情况下，保证系统的正确性（避免分叉）。与原始的 BFT 算法相比，算法复杂度从指数级降低到了多项式级，从而使得 BFT 算法的实际应用成为可能。实际上，Tenermint 就是 PBFT 的一个简化版本的实现。</p><h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><p>首先了解一下几个基本概念：（从区块链的视角）</p><ul><li>replica：即区块链节点，提供 “副本复制” 服务</li><li>client：向 primary 发起请求的客户端节点，在区块链中往往跟 primary 合二为一</li><li>primary：区块发起者，在收到请求后生成新区块并广播</li><li>backup：区块验证者，在收到区块后进行验证，然后广播验证结果进行共识</li><li>view：一个 primary 和多个 backup 形成一个 view，在该 view 上对某个区块进行共识</li><li>sequence number(n)：由 primary 指定的一个数字，可以理解为区块高度</li><li>checkpoint：如果某个 sequence number 对应的区块收到了超过 2/3 的确认，则称为一个 checkpoint</li></ul><p>另外，primary 是所有节点轮流做的，每个 view 上都会选出一个新的 primary。</p><h1 id="三阶段协议"><a href="#三阶段协议" class="headerlink" title="三阶段协议"></a>三阶段协议</h1><p>三阶段协议是 PBFT 的核心，参见下图：<br><img src="/2020/02/29/pbft-algorithm/20180814171323387.jfif" alt></p><p>从发起请求到最终收到 reply，中间的共识过程需要经过 3 个阶段：</p><ul><li>pre-prepare：primary 收到请求，生成新区块并广播</li><li>prepare：所有 replica 收到区块后，广播区块验证结果，同时等待接收超过 2/3 的节点的广播</li><li>commit：收到 2/3 的节点广播或者超时后，再次发送广播，同时再次等待接收超过 2/3 的节点的广播</li></ul><p>这里的逻辑有点绕：<br>第一次等待超过 2/3 的节点广播，是为了确认 “已经有超过 2/3 的节点收到区块了”。但是这只是你自己知道，别人并不知道啊，因此需要再发送一次广播，告诉别的节点 “我已经确认有超过 2/3 的节点收到区块啦”。而第二次等待超过 2/3 的节点广播，则是为了确认 “已经有超过 2/3 的节点确认 (有超过 2/3 的节点收到区块啦)”，此时说明已经达成共识，可以把该区块写到链上了。</p><h1 id="PBFT-状态机"><a href="#PBFT-状态机" class="headerlink" title="PBFT 状态机"></a>PBFT 状态机</h1><p>这个原文是没有图的，只能根据文字描述自行理解，还是挺复杂的：</p><p><img src="/2020/02/29/pbft-algorithm/20180814171405725.png" alt></p><p>图中的圆角矩形表示状态，六边形表示等待阶段，绿线代表正常流程，红线代表异常流程。下面一个一个的来介绍：</p><ul><li>wait request<ul><li>即等待请求状态，所有节点初始均处于该状态</li><li>primary 收到 REQUEST 消息后，会转换到 pre-prepare 状态</li><li>backup 收到区块后，会转换到 prepare 状态</li></ul></li><li>pre-prepare<ul><li>这个状态是 primary 专属的，primary 生成区块并广播 PRE-PREPARE 消息后，转换到 prepare 状态</li></ul></li><li>prepare<ul><li>进入该状态后，广播 PREPARE 消息，并等待 2f+1 个节点确认</li></ul></li><li>wait for 2f+1 prepare<ul><li>如果等到了 2f+1 个节点确认（accept 或 reject），转换到 commit 状态</li><li>如果超时，转换到 view change 状态</li></ul></li><li>commit<ul><li>进入该状态后，广播 COMMIT 消息，并等待 2f+1 个节点确认</li></ul></li><li>wait for 2f+1 commit<ul><li>如果等到了 2f+1 个节点确认（accept 或 reject），发送 REPLY 消息，转换回 wait request 状态</li><li>如果超时，转换到 view change 状态</li></ul></li><li>view change<ul><li>进入该状态后，广播 v+1 的 VIEW-CHNAGE 消息，等待接收 2f 个节点的 VIEW-CHANGE 消息</li></ul></li><li>wait for 2f view change<ul><li>这个状态比较复杂，可以分为以下 4 种情形：<ul><li>收到了 2f 个节点的 VIEW-CHANGE 消息，并且是新的 primary，广播 NEW-VIEW 消息，并转换到 pre-prepare 状态</li><li>收到了 2f 个节点的 VIEW-CHANGE 消息，并且是 backup，转换到 wait request 状态</li><li>接收超时，重新回到 view change 状态，广播 v+2 的 VIEW-CHANGE 消息</li><li>在收到 2f 个节点的 VIEW-CHANGE 消息之前，收到了 NEW-VIEW 消息，则转换到 prepare 状态</li></ul></li></ul></li></ul><p>需要注意的是，如果接收到了 NEW-VIEW 消息，则表示当前 view 未达成共识，需要在更高层的 view 上完成共识。因此，不管当前处于哪个阶段，都需要重新回到 prepare 状态。</p><h1 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h1><p>接下来就是介绍一下相关的数据结构了，主要是状态和消息。</p><h2 id="State"><a href="#State" class="headerlink" title="State"></a>State</h2><p><img src="/2020/02/29/pbft-algorithm/20180814171626304.png" alt></p><p>节点的状态主要包含三部分：</p><ul><li>世界状态（即最新区块信息）</li><li>消息日志</li><li>当前 view</li></ul><h2 id="Three-Phase-Protocol"><a href="#Three-Phase-Protocol" class="headerlink" title="Three Phase Protocol"></a>Three Phase Protocol</h2><p><img src="/2020/02/29/pbft-algorithm/20180814171638282.png" alt></p><p>这里列出了三阶段协议相关的消息结构，其中 PRE-PREPARE 消息包含新生成的区块，其他消息则主要包含一些 id、sequence number、区块内容摘要和签名等信息。</p><h2 id="VIEW-CHANGE"><a href="#VIEW-CHANGE" class="headerlink" title="VIEW-CHANGE"></a>VIEW-CHANGE</h2><p><img src="/2020/02/29/pbft-algorithm/20180814171712980.png" alt></p><p>VIEW-CHANGE 消息包含的内容比较多：<br>首先需要基于一个稳定的 checkpoint，因此需要包含 2f+1 个 CHECKPOINT 消息以证明该 checkpoint 是有效的。<br>然后，在该 checkpoint 之上的所有 sequence number，都需要打包对应的 PRE-PREPARE 消息以及 2f 个 PREPARE 消息。</p><h2 id="NEW-VIEW"><a href="#NEW-VIEW" class="headerlink" title="NEW-VIEW"></a>NEW-VIEW</h2><p><img src="/2020/02/29/pbft-algorithm/20180814171729918.png" alt></p><p>NEW-VIEW 消息首先需要包含 2f+1 个 VIEW-CHANGE 消息，以证明确实有超过 2/3 的节点同意在更高的 view 上进行新一轮共识。<br>然后，根据收到的所有 VIEW-CHANGE 消息中的 checkpoint 信息，找出最小值 min_s 和最大值 max_s，打包该区间内的每一个 sequence number 对应的 PRE-PREPARE 消息。<br>特别的，为了减少重复验证，如果在某个 sequence number 上从未进行过 view change（即第一轮就达成了共识），则 PRE-PREPARE 中包含一个特殊的 null 请求的摘要信息。</p><p>具体逻辑参见下图：<br><img src="/2020/02/29/pbft-algorithm/20180814171838867.png" alt></p><p>如果想要了解更多的算法细节，可以阅读论文原文：<br><a href="http://pmg.csail.mit.edu/papers/osdi99.pdf" target="_blank" rel="noopener">http://pmg.csail.mit.edu/papers/osdi99.pdf</a></p>]]></content>
      
      
      <categories>
          
          <category> 区块链 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PBFT </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>区块链初探</title>
      <link href="/2020/02/29/blockchain-pbft-concept/"/>
      <url>/2020/02/29/blockchain-pbft-concept/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文由 <a href="http://ksria.com/simpread/" target="_blank" rel="noopener">简悦 SimpRead</a> 转码， 原文地址 <a href="https://www.cnblogs.com/newton/p/7645082.html" target="_blank" rel="noopener">https://www.cnblogs.com/newton/p/7645082.html</a></p></blockquote><p><strong>区块链[&amp;比特币]概念</strong></p><p>拜占庭问题：讨论如何在远程协商且有干扰信息的情况下整个系统达成正确决策的问题。 <a href="http://www.8btc.com/baizhantingjiangjun" target="_blank" rel="noopener">拜占庭将军问题深入探讨</a> 。一般地，把故障（不响应）的情况称为“非拜占庭错误”，恶意响应的情况称为“拜占庭错误”，对应的节点称为拜占庭节点。设总节点数N，故障节点f，PBFT场景需满足N&gt;=3f+1；所以在prepare和commit两个阶段必须收到至少2f+1(包括自己) 个节点的消息，才可认为多于<strong>故障和恶意节点</strong>的<strong>正常节点</strong>发回了响应，并有消息至少占据f+1数量的节点，从而达成共识。——注意，达成共识并不表示最终结果的正确性，而是只要得出这个最终结果即可。</p><p>两军问题：信道的不可靠（信息存在被篡改和丢失的可能）使得两军问题无解。</p><p><em>倘若1号蓝军（简称1）向2号蓝军（简称2）派出了通信兵，若1要知道2是否收到了自己的信息，1必须要求2给自己传输一个回执，说“你的信息我已经收到了，我同意你提议的明天早上10点9分准时进攻”。然而，就算2已经送出了这条信息，2也不能确定1就一定会在这个时间进攻，因为2发出的回执1并不一定能够收到。所以，1必须再给2发出一个回执说“我收到了”，但是1也不会知道2是否收到了这样一个回执，所以1还会期待一个2的回执。虽然看似很可笑，但在这个系统中永远需要存在一个回执，这对于两方来说都并不一定能够达成十足的确信。更要命的是，我们还没有考虑，通信兵的信息还有可能被篡改。</em></p><p>这有点类似于《三体》里的猜疑链，除非我们/文明之间如三体人一样可以敞开心扉无障碍交流（可靠信道）。</p><p><em>不幸的是，两军问题作为现代通信系统中必须解决的问题，我们尚不能将之完全解决，这意味着你我传输信息时仍然可能出现丢失、监听或篡改的情况。但我们能不能通过一种相对可靠的方式来解决大部分情形呢？这需要谈到TCP协议。事实上，搜索“两军问题与三次握手”，您一定可以找到大量与TCP协议相关的内容。TCP协议中，A先向B发出一个随机数x，B收到x了以后，发给A另一个随机数y以及x+1作为答复，这样A就知道B已经收到了，因为要破解随机数x可能性并不大；然后A再发回y+1给B，这样B就知道A已经收到了。这样，A和B之间就建立一个可靠的连接，彼此相信对方已经收到并确认了信息。而事实上，A并不会知道B是否收到了y+1；并且，由于信道的不可靠性，x或者y都是可能被截获的，这些问题说明了即使是三次握手，也并不能够彻底解决两军问题，只是在现实成本可控的条件下，我们把TCP协议当作了两军问题的现实可解方法。</em></p><p>FLP Impossibility：可参看<a href="https://blog.csdn.net/chen77716/article/details/27963079/" target="_blank" rel="noopener">FLP Impossibility</a>，文中比较难以理解的是——F0属于D，因为D是”确定“的，E0是0-valent的，无论E0从F0可达，还是F0从E0可达，则F0必定是0-valent的——“确定”即表示后续能且只能做出一个决议，因为E0是0-valent，若E0从F0可达（即E0是F0的后续），那么F0不能演化出1-valent，也就是说F0自身不能是1-valent（若F0是1-valent，那么任意事件e应用到失效的p上，结果还是1-valent，这将反推得D是“不确定”的）；F0从E0可达同理。</p><p>Diffie-Hellman算法可以使得在不安全信道上安全的交换密钥，亦是非对称加密算法的开端。</p><p><em>普遍大家都认为公钥密码体制是迪菲(W.Diffie)和赫尔曼(E.Hellman)发明的，可鲜为人知的是，默克勒(R.C.Merkle)甚至在他俩之前的1975年就提出了类似的思想，尽管其文章是于1978年发表的，但投稿比较早。因此，公钥密码体制的创始人应该是他们三人。 当然，他们三人只是提出了一种关于公钥密码体制与数字签名的思想，而没有真正实现。不过，他们确实是实现了一种体现公钥密码体制思想、基于离散对数问题的、在不安全的通道上进行密钥形成与交换的新技术。</em></p><p>比特币的方式每秒可以处理多少笔交易？最理想状态下，平均每笔交易225 字节。在1M区块限制下，一般平均10分钟可以打包大约 4400 笔交易。每秒大约7.3笔交易，实际交易平均大小是这个的一倍，那么容量减半，也就是每秒大约 3.6 笔交易。</p><p>一笔交易的可读格式如下：</p><pre><code>  {    &quot;version&quot;: 1,    &quot;locktime&quot;: 0,    &quot;vin&quot;: [      {        &quot;txid&quot;:&quot;7957a35fe64f80d234d76d83a2a8f1a0d8149a41d81de548f0a65a8a999f6f18&quot;,        &quot;vout&quot;: 0,        &quot;scriptSig&quot;: &quot;3045022100884d142d86652a3f47ba4746ec719bbfbd040a570b1deccbb6498c75c4ae24cb02204b9f039ff08df09cbe9f6addac960298cad530a863ea8f53982c09db8f6e3813[ALL] 0484ecc0d46f1918b30928fa0e4ed99f16a0fb4fde0735e7ade8416ab9fe423cc5412336376789d172787ec3457eee41c04f4938de5cc17b4a10fa336a8d752adf&quot;,       &quot;sequence&quot;: 4294967295     }  ],   &quot;vout&quot;: [     {       &quot;value&quot;: 0.01500000,       &quot;scriptPubKey&quot;: &quot;OP_DUP OP_HASH160 ab68025513c3dbd2f7b92a94e0581f5d50f654e7 _EQUALVERIFY OP_CHECKSIG&quot;     },     {       &quot;value&quot;: 0.08450000,       &quot;scriptPubKey&quot;: &quot;OP_DUP OP_HASH160 7f9b1a7fb68d60c536c2fd8aeaa53a8f3cc025a8 _EQUALVERIFY OP_CHECKSIG&quot;,     }   ] }</code></pre><p>交易手续费：一笔交易设置了输入输出（UTXO），若输出总额小于输入总额，那么差额就作为手续费给到[打包到区块中的]矿工。因此，矿工会优选手续费大的交易；且由于区块大小一定，若一个交易有很多个输入输出（如以非常多的小额输入汇总到一个输出），即该笔交易数据size较大，矿工也许会比较该笔交易的手续费与多笔小size的交易手续费之和的大小。总之，除挖矿奖励的比特币外，矿工都会希望自己挖到的区块记录的交易有更多的手续费。若链上交易频繁，那些手续费少或者为0的交易甚至都不会被记录，从而得不到确认。</p><p>_在手动创建交易时，务必注意输入、输出的值，非常容易犯错的是忘记构造找零输出。曾经有人构造交易时忘记找零，发生了支付 200 BTC 的矿工费的人间惨剧，所幸的是收录该笔交易的Block由著名挖矿团队“烤猫（Friedcat）”挖得，该团队非常厚道的退回了多余费用_。</p><p>比特币的交易验证引擎依赖于两类脚本来验证比特币交易：锁定脚本（上述代码scriptPubKey）和解锁脚本（上述代码scriptSig）。锁定脚本是输出的一个字段，而解锁脚本是输入的一个字段，解锁的是上笔输出的锁定脚本。可以理解为解锁脚本作为参数传入锁定脚本，若最终得到的结果为true，那么表示该锁定脚本关联的交易输出可以作为该解锁脚本关联的交易输入，即能提供正确的解锁脚本的账号才可使用锁定脚本锁定的输出。矿工亦是据此验证一个交易是否成立。上述脚本格式为P2PKH——支付到公钥地址模式（还有P2SH，支付到脚本模式，使用多重签名就需要用到这种模式），在P2PKH模式下，scriptSig格式为_[签名的字节数]［签名］0×01 [公钥的字节数] [公钥]_，scriptPubKey格式为_OP_DUP OP_HASH160 （0×14） [一个20字节的哈希值] OP_EQUALVERIFY OP_CHECKSIG_。</p><p>我们可以查看上述交易的前一笔交易的输出：</p><pre><code> &quot;vout&quot;: [    {      &quot;value&quot;: 0.10000000,      &quot;scriptPubKey&quot;: &quot;OP_DUP OP_HASH160 7f9b1a7fb68d60c536c2fd8aeaa53a8f3cc025a8 OP_EQUALVERIFY OP_CHECKSIG&quot;    }  ]</code></pre><p>第4行的20字节的16进制串_7f9b1a7fb68d60c536c2fd8aeaa53a8f3cc025a8_是收款方的地址，乃是收款方公钥经过二次hash后得到的。</p><p><em>为什么不直接使用公钥呢，这是出于安全考虑。我们知道，可以从私钥轻松地得到公钥，反之则非常困难。虽然通过公钥很难得到私钥，但为了将风险降到最低，在交易过程中，我们可以将公钥hash之后作为收款地址发给对方；更进一步，比特币转账每次都是彻底把原来账户中的币全部转走（除非一个账户付款给自己，如找零），因此只要我不重复使用同一个公钥，用完就扔掉，就不用担心别人拿到我的公钥后能干啥：如果高手不能很快的在我发布交易后根据里面的公钥算出私钥，一旦交易完成，公钥对应的就是一个空账户了。</em></p><p>交易验证过程简单地说就是：</p><ol><li>把scriptSig中的公钥同样经过二次hash后得到的数据与前一笔交易的scriptPubKey的哈希值比对，若相等则说明公钥有效；</li><li>使用公钥解密scriptSig中的签名，得到的结果若与当初私钥签名的内容（目前比特币采用的是当前交易的全部or部分数据，取决于SIGHASH标志字节，scriptSig中指定）相同，则交易有效[，不考虑其它非法情况比如交易输出&gt;输入]（矿工便可将该交易打包）。</li></ol><p>一般钱包会使用SIGHASH_ALL标志（0x01）进行签名，表示Signature applies to all inputs and outputs。指定不同的SIGHASH标志可以实现特殊的业务场景，比如ALL|ANYONECANPAY（0x81，Signature applies to one input and all outputs）可以实现某种众筹形式：试图筹集资金的人可以用单笔输出来构建一个交易，单笔输出将“目标”金额付给众筹发起人。这样的交易显然是无效的，因为它没有输入。但是现在其他人可以通过添加自己的输入作为捐赠来修改它，他们用ALL | ANYONECANPAY签署自己的输入，除非收集到足够的输入以达到输出的价值，否则交易[数据]无效，可以把每次捐赠看作是一项“抵押”，直到募集到整个目标金额募款人才能真正收取（即将交易数据发送到比特币网络，满足输入&gt;=输出才能被矿工打包记录）。</p><p>在签名过程中，会先 generates an <em>ephemeral</em> (temporary) private public key pair。为何要另外生成一对临时密钥对，而不使用已有的公私钥，现在我还没理解进去。</p><p>私钥就是一个随机选出的数字。比特币私钥空间的大小是2^256，这是一个非常大的数字。用十进制表示的话，大约是10^77，而可见宇宙被估计只含有10^80个原子。</p><p>通过椭圆曲线乘法可以从私钥计算得到公钥，这是不可逆转的过程：K = k * G 。其中k是私钥，G是被称为生成点的常数点，而K是所得公钥。比特币使用了secp256k1标准所定义的一种特殊的椭圆曲线和一系列数学常数，所有比特币用户的生成点是相同的。</p><p>公钥的格式：按是否压缩可分为非压缩格式和压缩格式。我们知道，公钥是在椭圆曲线上的一个点，由一对坐标（x，y）组成。非压缩公钥通常表示为前缀04紧接着两个256比特的数字，组成格式为04 x y共520bit。引入压缩格式公钥是为了减少比特币交易的字节数，从而可以节省那些运行区块链数据库的节点磁盘空间——压缩格式只存储公钥的x坐标值，y坐标可以通过解椭圆曲线的方程求得，前缀02/03分别对应y是偶数/奇数的情况。</p><p>为了存储安全，私钥有必要再次加密。BIP0038提出了一个通用标准，使用一个[强]口令加密私钥并使用Base58Check对加密的私钥进行编码。这样就算别人获得了你的私钥（加密过的），但不知道口令[密码]依然无用。</p><p><strong>P2P网络</strong></p><p>当一个节点（如比特币钱包客户端）启动后，如何加入到比特币网络中呢，即怎样才能与已在比特币网络中的节点建立连接。一种方式是通过已知的DNS服务器，这些DNS服务器提供比特币节点的IP地址列表；或者指定至少一个已知的比特币节点的IP地址。目前你还不能期望一个孤独的节点连入Internet后自己能很快寻找到其它的比特币节点。</p><p><strong>SPV指的是“支付验证“，而不是“交易验证”。</strong>这两种验证有很大区别。<br>“交易验证”非常复杂，涉及到验证是否有足够余额可供支出、是否存在双花、脚本能否通过等等，通常由运行完全节点的矿工来完成。<br>“支付验证”则比较简单，只判断用于“支付”的那笔交易是否已经被验证过（已经被矿工打包），并得到了多少的算力保护（多少确认数）。这里涉及到Merkle Tree的概念，将数据块分段hash，然后相邻两段[或多段]的hash拼接后再hash，最终得到一个根hash，这样就组成了一棵Merkle Tree。我们可以依靠它校验局部数据，而不需要对整个数据块进行校验，参看<a href="https://www.jianshu.com/p/2b082157b3b0" target="_blank" rel="noopener"> 大话Neo系列:Merkle Tree</a>。 </p><p><strong>哈希算法</strong>在比特币中的应用几乎是方方面面，主要包括SHA256和RIPEMD160，比特币将这两个哈希算法的应用组合成两个函数：hash256(d)=sha256(sha256(d))和hash160(d)=ripemd160(sha256(d))，其中d为待哈希的字节数组，两者分别生成256位（32字节）和160位（20字节）的16进制数值。hash256主要用于生成标志符，如区块ID，交易ID等，而hash160主要用于生成比特币地址。<br>值得一提的是，为什么两个函数都是做两次哈希呢？对于hash160比较认同的答案是ripemd160可以使得生成的地址更短，但是只做ripemd160一次哈希可能会存在安全漏洞所以同时使用sha256起到安全加固；至于hash256使用两次sha256哈希算法的原因来源于sha1算法，由于一次sha1哈希存在被生日攻击（birthday attack）的风险，所以当使用sha1运算时一种有效方式就是做两次sha1哈希，sha256本身并不存在生日攻击漏洞，但是防御性的使用两次sha256哈希借鉴于sha1.</p><p>参考资料：<a href="http://book.8btc.com/books/6/masterbitcoin2cn/_book/ch04.html" target="_blank" rel="noopener">精通比特币（第二版）</a> 英文原版：<a href="https://github.com/bitcoinbook/bitcoinbook" target="_blank" rel="noopener">https://github.com/bitcoinbook/bitcoinbook  </a></p><hr><p><strong>涉及到的部分数学知识</strong></p><p>a≡b(modc)a≡b(modc)a\equiv b\pmod{c}：a和b除以c后余数相同。</p><p>线性同余方程：ax≡b(modn)ax≡b(modn)ax\equiv b\pmod{n}，当且仅当b能够被a与n的最大公约数整除（记作gcd(a,n) | b）时，此方程有解。这时，如果 x0 是方程的一个解，那么所有的解可以表示为：{x0+kn/d|(k∈z)}，其中 d 是a 与 n 的最大公约数。在模 n 的完全剩余系 {0,1,…,n-1} 中，恰有 d 个解。例如，在方程5x ≡ 2 (mod 6)中， d = gcd(5,6) = 1，1 整除 2，因此方程在{0,1,2,3,4,5} 中恰有一个解: x=4。</p><p>对于[一元]线性同余方程组，中国剩余定理给出了有解的判定条件，并用构造法给出了在有解情况下解的具体形式。</p><p>原根：如果 a 与 n 是互质的整数且n&gt;0，那么当ordna=φ(n)ordna=φ(n)ord_na=\varphi(n)时，称a为模n的原根。若a是n的原根，那么aimodn,其中(i∈[1,n−1],a∈[2,n−1])aimodn,其中(i∈[1,n−1],a∈[2,n−1])a^i \bmod n,其中(i\in[1,n-1],a\in[2,n-1])的<strong>结果互不相同</strong>。也可从另个方面理解，P为素数，i、j为整数，其中i≠j,且i,j∈[1,P−1]i≠j,且i,j∈[1,P−1]i \ne j, 且 i,j \in [1,P-1]，若对于满足上述条件的任意i、j，有gimodP≠gjmodPgimodP≠gjmodPg^i \bmod P \ne g^j \bmod P，则 g 就是 P 的原根。</p><p>更多阶与原根的知识可参看 <a href="https://blog.csdn.net/fuyukai/article/details/50894609" target="_blank" rel="noopener">数论之原根</a>。</p><p>Diffie-Hellman算法：一种秘钥交换算法，它是一种建立秘钥的方法，而不是加密方法，这种秘钥交换技术的目的在于使两个用户安全的交换一个秘钥。按上述原根的性质，可知如果a是素数p的一个原根，那么数值amodp,a2modp,⋯,ap−1modpamodp,a2modp,⋯,ap−1modpa \bmod p,a^2 \bmod p,\cdots,a^{p-1} \bmod p 是各不相同的整数，并且以某种排列方式组成了从1到p-1的所有整数。可参看 <a href="https://blog.csdn.net/lee244868149/article/details/51790397" target="_blank" rel="noopener">Diffie-Hellman（迪菲-赫尔曼）秘钥交换</a>。</p><p><em>涉及引理：若amodb≡namodb≡na \bmod b \equiv n，则akmodb≡nkmodbakmodb≡nkmodba^k \bmod b \equiv n^k \bmod b。</em></p><p><em>证明：</em></p><p><em>因为amodb≡namodb≡na \bmod b \equiv n，则必然存在唯一整数q使得 a=qb+n （带余除法基本原理）</em></p><p><em>于是ak=(qb+n)kak=(qb+n)ka^k=(qb+n)^k，将(qb+n)k(qb+n)k(qb+n)^k二项式展开，可以发现展开项除nknkn^k外，其余项b的次数都大于零，可得除以b的余数必然由nknkn^k这一项产生</em></p><p><em>所以akmodb≡nkmodbakmodb≡nkmodba^k \bmod b \equiv n^k \bmod b，证毕</em></p><p>RSA加密算法：参看 <a href="http://www.ruanyifeng.com/blog/2013/06/rsa_algorithm_part_one.html" target="_blank" rel="noopener">阮一峰：RSA算法原理（一）</a>、<a href="http://www.ruanyifeng.com/blog/2013/07/rsa_algorithm_part_two.html" target="_blank" rel="noopener">RSA算法原理（二）</a></p><hr><p><strong>其它</strong></p><p>复式记账法：Asset（资产） = Liability（负债） + Equity（股东权益）。等式左边可理解为[公司]债务，右边可理解为[股东和其他投资方的]债权，可以理解为公司本身是没钱的，公司赚的钱都是属于股东的。</p><p>个人理解，一个好处是便于数据的统计汇总，它将一笔经济业务格式化为借&amp;贷。借表示资金目前的状态，贷表示资金的来源。整个借贷分录，描述出一笔经济业务的资金运行情况，包括了业务种类（即会计科目）、涉及金额和资金运行方向，也就是用会计的语言描述了一笔经济业务。这比纯语言记录如“老李借给我100块钱”更规范，也便于工具[&amp;自己]汇总对账。</p><p><em>另一个角度理解复式记账法，可以建立一个“主体观”，要明白记账的“主体”是什么？记账的主体是“公司”，不是股东，也不是债权人（这就是公司的法人独立性）。所以资源流入的时候，公司资产增加。但是“公司” 是属于股东的，公司有一部分资产也是属于债权人的，所以每一笔资源流入，必然对应股东权益增加，或者债权人债权增加（不考虑资产内部互转等情况）；流出亦然。也就是说，公司每一笔业务导致的资源（财、物）流动，复式记账法不仅给“主体”做了登记，还给资源的归属做了登记。为什么要这么复杂？因为公司法人独立，公司资产与股东财产分离，才能做到公司债务与股东责任分离。公司可以破产，因为经营的主体是“公司”而非股东个人，所以股东不必“卖房卖车卖儿卖女”的去还债；所以股东虽然是公司所有者，但是非法挪用公司财产照样是犯罪。这个“主体观”，不仅可以帮助理解复式记账法，还是以后学习更复杂的企业合并、报表合并、股权投资核算的有力工具。[<a href="https://www.zhihu.com/question/20718557/answer/74622257" target="_blank" rel="noopener">来自知乎</a>，相关问题：<a href="https://www.zhihu.com/question/20718557" target="_blank" rel="noopener">复式记账（复式簿记）的基本原理是什么？</a>]</em></p><p>通货膨胀导致货币缓慢但不可避免的贬值，这是一种隐性税收的形式，惩罚在银行存钱的人从而实现解救债务人（包括政府这个最大的债务人）。 政府控制下的货币容易遭受债务发行的道德风险，之后可能会以牺牲储蓄者为代价，通过贬值来抹去债务。</p><p>以太坊全节点中，都保存有完整的区块链数据。以太坊不仅将交易数据保存在链上，编译后 的合约代码同样也保存在链上，同时其还提供了一个虚拟机来执行合约代码。感性认识：<a href="https://bitshuo.com/topic/587e03c44dea36e72c1b381b" target="_blank" rel="noopener">深入解析调用合约的三种方法</a>、<a href="https://cloud.tencent.com/developer/news/237541" target="_blank" rel="noopener">序列8 智能合约能自动触发吗？-智能合约平台的本质</a></p><p>一般情况下，DApp还是需要中心服务器，用于同区块链/以太坊节点交互，非用户数据存储在本地，用户数据保存在链上。若有成千上万个DApp运行在主链上，将在计算和存储两方面对主链产生压力，可使用侧链架构，即每一个Dapp就是一条侧链，侧链可以有相对独立的区块链和节点网络，不同DApp之间互不影响，更合理。</p><p>寄存器是中央处理器内的组成部份。它们可用来暂存指令、数据和位址。在中央处理器的控制部件中，包含的寄存器有指令寄存器(IR)和程序计数器(PC)。在中央处理器的算术及逻辑部件中，包含的寄存器有累加器(ACC)。</p><p>堆栈：堆和栈是两种内存分配的两个统称，可能有很多种不同的实现方式。每种语言针对其有基本的设计原则，如栈通常后进先出（LIFO）。堆都是动态分配的，没有静态分配的堆。栈有两种分配方式：静态分配和动态分配。静态分配是编译器完成的，比如局部变量的分配；栈的动态分配和堆是不同的，他的动态分配是由编译器进行释放，无需我们手工实现。栈是机器系统提供的数据结构，计算机会在底层对栈提供支持，分配专门的寄存器存放栈的地址，压栈出栈都有专门的指令执行，这就决定了栈的效率比较高。栈通常用于存取函数参数值、局部变量值以及指令地址等，主要保证逻辑按预期顺序执行；而堆简单的多，只是用于数据的存取。理解堆栈的概念还是得从早期的硬件和语言历史回顾，随着计算机技术的发展，这两者在软硬件的层面，在不同场景下都有不同的体现。<a href="http://blog.csdn.net/luyuncsd123/article/details/9079147" target="_blank" rel="noopener">C/C++中的变量存储类别以及内存分配 </a></p><p>指令系统分成堆栈型和寄存器型。不光这两种，指令系统共有四种分类，堆栈型，累加器型，寄存器-存储器型和寄存器-寄存器型。分类的依据是操作数的来源。堆栈型默认的操作数都在栈顶，累加器型默认一个操作数是累加器，寄存器-存储器型的操作数可以是寄存器或者内存，寄存器-寄存器型除了访存指令，操作数都是寄存器。</p><p>进程，线程，协程：进程和线程大家很熟悉。进程拥有自己独立的堆和栈，既不共享堆，亦不共享栈，进程由操作系统调度；线程拥有自己独立的栈，共享堆，不共享栈，线程亦由操作系统调度；协程主要是针对单线程的一个概念（如Js、NodeJs、Python由于GIL导致的伪多线程），常用的一个场景是IO阻塞时，程序控制线程不傻傻等待，而是去执行其它任务，等IO操作完毕再控制线程回来继续操作，由于是单线程，所以也不涉及到由于系统调度导致的性能损耗。在编程层面上来说，协程的概念偏向于已同步编程的模式实现异步处理的编程模式，避免了多层回调代码嵌套的问题。协程的模式容易让人联想到C#的await/async，其实两者虽然解决的问题差不多，但是C#是多线程，若回调到达时，之前的线程仍在忙其它事情，线程池完全可以派另外的线程处理后续步骤，虽然多了线程上下文（主要是栈数据，刷新寄存器）切换的开销，但不用死等之前线程。参考资料 <a href="https://zhuanlan.zhihu.com/p/31410589" target="_blank" rel="noopener">事件驱动与协程：基本概念介绍</a> （虽然其中内容不太准确，但是意思到位了）。</p><p>多个协程对应到一个线程才有意义，就如同一个进程包含多个线程。一个cpu内核同一时间只能执行一个进程/线程，因此在一个内核上的多线程执行其实效率反而比串行执行低，只是给用户一种并发的错觉；协程也同理，虽然貌似多个协程并行执行，其实最终还是落到一个线程上，不过比掩耳盗铃的多线程切换要省时省力（无需切换线程，省去了内核调度），并发的感觉上似乎也更加快了。当然多个协程可以对应到多个线程，特别是在当前多核cpu场景下，一般协程数多于线程数才有使用协程的意义。Go语言中的Goroutine可看作协程的一种实现，参看：<a href="http://blog.51cto.com/nxlhero/1835887" target="_blank" rel="noopener">理解Goroutine</a></p><p>指针：</p><pre><code>void Add(int * a)   // a 是一个int型的指针,a指的地址存放的是int型的数据{  a    // 取指针a的值(即其指向内容的地址)  *a   // 取指针a指向的内容  &amp;a   // 取存放指针a的值的地址}</code></pre><p>为什么会有指针。从广义上讲，在编码时，我们也可以认为普通变量是指向具体内存的指针，但是代码编译后变量名会被替换为[虚拟]内存地址或者各种寄存器，所以变量只是给程序员编程时操作数据用的，但是有时我们需要操作的是数据所在的内存地址，这个时候普通的变量就没办法了，于是有了我们平常所说的指针的概念。</p><p>C++还有引用的概念，可以理解为一个变量的别名，指向同一块内存（即使用引用不会创建对象副本），主要用在方法参数和返回值。不同于C#，C#一开始就在底层区分了值类型和引用类型，而C++传递变量名默认就是值传递（不管是什么数据类型）。很多人对指针和引用傻傻分不清，虽然指针也可以实现引用的功能（毕竟指针直接操作内存地址，你说啥功能实现不了），但是引用更符合它所代表的使用场景。</p><p>vector：C++中的一种数据结构，一般作为动态size的数组使用。vector的扩充机制：按照容器现在容量的一倍进行增长。 vector容器分配的是一块连续的内存空间，每次容器的增长，并不是在原有连续的内存空间后再进行简单的叠加， 而是重新申请一块更大的新内存，并把现有容器中的元素逐个复制过去，然后销毁旧的内存。 这时原有指向旧内存空间的迭代器已经失效，所以当操作容器时，迭代器要及时更新。</p><p> 其它资料： <a href="https://thecodeway.com/blog/?p=964" target="_blank" rel="noopener">一个简单的DH密钥协商算法的实现</a></p>]]></content>
      
      
      <categories>
          
          <category> 区块链 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PBFT </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo Setup</title>
      <link href="/2020/02/29/hexo-setup/"/>
      <url>/2020/02/29/hexo-setup/</url>
      
        <content type="html"><![CDATA[<p>Hexo安装及简单配置使用</p><h3 id="安装目录执行"><a href="#安装目录执行" class="headerlink" title="安装目录执行"></a>安装目录执行</h3><pre><code class="bash">$ npm install hexo -g$ hexo -v$ hexo init$ npm install$ hexo g$ hexo s$ hexo clean$ hexo d</code></pre><h3 id="插件"><a href="#插件" class="headerlink" title="插件"></a>插件</h3><pre><code class="bash">$ npm install hexo-deployer-git --save$ npm i -S hexo-generator-json-content$ npm install hexo-generator-search --save# post_asset_folder:true$ npm install hexo-asset-image --save$ npm install https://github.com/CodeFalling/hexo-asset-image --save</code></pre><h3 id="其它命令"><a href="#其它命令" class="headerlink" title="其它命令"></a>其它命令</h3><pre><code class="bash"># 使用分类和标签，执行一次$ hexo new page categories$ hexo new page tags# 添加自定义页面$ hexo new page &quot;page name&quot;</code></pre><h3 id="MathJax数学公式"><a href="#MathJax数学公式" class="headerlink" title="MathJax数学公式"></a>MathJax数学公式</h3><p>修改 _config.yml</p><pre><code class="yml"># MathJax 数学公式支持mathjax:  on: true #是否启用  per_page: false # 若只渲染单个页面，此选项设为false，页面内加入 mathjax: true</code></pre><p>考虑到页面的加载速度，支持渲染单个页面。<br>设置 <code>per_page: false</code> ,在需要渲染的页面内 加入 <code>mathjax: true</code></p><blockquote><p><strong><code>注意:</code></strong><br>由于hexo的MarkDown渲染器与MathJax有冲突，可能会造成矩阵等使用不正常。所以在使用之前需要修改两个地方<br>编辑 <code>node_modules\marked\lib\marked.js</code> 脚本</p></blockquote><ol><li>将451行 ，这一步取消了对 <code>\\,\{,\}</code> 的转义(escape)<pre><code class="js">escape: /^\\([\\`*{}\[\]()# +\-.!_&gt;])/,改为escape: /^\\([`*\[\]()# +\-.!_&gt;])/, </code></pre></li><li>将459行，这一步取消了对斜体标记 _ 的转义<pre><code class="javascript">em: /^\b_((?:[^_]|__)+?)_\b|^\*((?:\*\*|[\s\S])+?)\*(?!\*)/,改为em:/^\*((?:\*\*|[\s\S])+?)\*(?!\*)/,</code></pre></li></ol><h3 id="修改过的theme文件"><a href="#修改过的theme文件" class="headerlink" title="修改过的theme文件"></a>修改过的theme文件</h3><ul><li>themes\3-hexo\layout\indexs.md</li><li>themes\3-hexo\source\css_partial\post.styl</li></ul>]]></content>
      
      
      <categories>
          
          <category> 安装部署 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
